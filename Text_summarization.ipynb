{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of Copy of Text_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEq-oYpmSM5r"
      },
      "source": [
        "# Text Summerization - Encoder Decoder with Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iFfGxm4XgZl"
      },
      "source": [
        "### Importing Basic libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8XfN5xQA6PZ",
        "outputId": "f8195bcb-f99d-40a9-c2ce-514f7cbef797"
      },
      "source": [
        "!wget 'http://nlp.stanford.edu/data/glove.42B.300d.zip'\n",
        "!unzip '/content/glove.42B.300d.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-17 15:39:21--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2021-08-17 15:39:21--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2021-08-17 15:39:21--  http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  5.15MB/s    in 5m 53s  \n",
            "\n",
            "2021-08-17 15:45:14 (5.07 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n",
            "Archive:  /content/glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvLzgRrb2QAa",
        "outputId": "8241999f-ce51-4468-aa26-b7039309cd6b"
      },
      "source": [
        "pip install contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.2.0-py3-none-any.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 57.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85455 sha256=a96de15d9ecca976f7f68e2f09923d137650b75e2d5cbf2f77be9fa0c74ac6e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uEL8_WrZ7-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2730edf-7bbc-4cda-bbd3-c21913b67a5c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWiyPJQyqU0BHS58Pi_y4LqymjVA2RJXFlZLKhWF_afDtQkFNtRDGbU\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lisXNzYrYOoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff65cf3-36bb-49c2-a6c3-08070c9233a0"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import contractions\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras import backend as K \n",
        "from tensorflow.python.keras.layers import Layer\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj3lfncbgBoK"
      },
      "source": [
        "!cp /content/drive/MyDrive/news_summary_more.csv /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSr24NviXqio"
      },
      "source": [
        "### Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3NFHA0CYOoZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "62ae165e-a714-4be4-cedc-a23e8037256f"
      },
      "source": [
        "data_path = '/content/news_summary_more.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           headlines                                               text\n",
              "0  upGrad learner switches to career in ML & Al w...  Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1  Delhi techie wins free food from Swiggy for on...  Kunal Shah's credit card bill payment platform...\n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  New Zealand defeated India by 8 wickets in the...\n",
              "3  Aegon life iTerm insurance plan helps customer...  With Aegon Life iTerm Insurance plan, customer...\n",
              "4  Have known Hirani for yrs, what if MeToo claim...  Speaking about the sexual harassment allegatio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mis8W95SAZ5_"
      },
      "source": [
        "data.drop_duplicates(subset=['headlines'],inplace=True)\n",
        "data.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV8b6w9YYOoa"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = ' '.join([contractions.fix(word) for word in text.split(\" \")])    \n",
        "    \n",
        "    tokens = [w for w in text.split() if not w in stop_words]\n",
        "    text = \" \".join(tokens)\n",
        "    text = text.replace(\"'s\",'')\n",
        "    text = text.replace(\".\",'')\n",
        "    text = re.sub(r'\\(.*\\)','',text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9. ]',' ',text)\n",
        "    text = re.sub(r'\\.','. ',text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewSx5cepYOob",
        "outputId": "55b255a6-367f-4443-8184-650066137e32"
      },
      "source": [
        "data['headlines'] = data['headlines'].apply(preprocess)\n",
        "data['text'] = data['text'].apply(preprocess)\n",
        "data['headlines'] = data['headlines'].apply(lambda x : '_START_ '+ x + ' _END_')\n",
        "\n",
        "for i in range(2):\n",
        "    print('Summary:', data['headlines'][i],'Text:', data['text'][i], sep='\\n')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary:\n",
            "_START_ upgrad learner switches career ml al 90 salary hike _END_\n",
            "Text:\n",
            "saurav kant alumnus upgrad iiit b pg program machine learning artificial intelligence sr systems engineer infosys almost 5 years work experience program upgrad 360 degree career support helped transition data scientist tech mahindra 90 salary hike upgrad online power learning powered 3 lakh careers\n",
            "\n",
            "Summary:\n",
            "_START_ delhi techie wins free food swiggy one year cred _END_\n",
            "Text:\n",
            "kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending 2000 cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cultfit more\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb68xRjGNP8z"
      },
      "source": [
        "headlines_length = [len(x.split()) for x in data.headlines]\n",
        "text_length = [len(x.split()) for x in data.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "4exx0vZpoZDp",
        "outputId": "4fcef4de-8331-4731-b6af-be6b525e8351"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
        "ax1.hist(headlines_length, bins = 20)\n",
        "ax2.hist(text_length, bins = 20)\n",
        "\n",
        "ax1.title.set_text(\"Words in Headlines\")\n",
        "ax2.title.set_text(\"Words in Text\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J6b2-BXoasR"
      },
      "source": [
        "### Embedding Matrix from Glove\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vLovzKr0m5S"
      },
      "source": [
        "glove_size = 300\n",
        "f = open('/content/glove.42B.300d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KulasZGc0nDp"
      },
      "source": [
        "embeddings_index = dict()\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tembeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JA07ZzL0nhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5535e162-8446-4832-a2e9-82c5eb2dd588"
      },
      "source": [
        "words_source_train = []\n",
        "for i in data['text'] :\n",
        "  words_source_train.extend(i.split(' '))\n",
        "\n",
        "print(\"all the words in the corpus\", len(words_source_train))\n",
        "words_source_train = set(words_source_train)\n",
        "print(\"the unique words in the corpus\", len(words_source_train))\n",
        "inter_words = set(embeddings_index.keys()).intersection(words_source_train)\n",
        "print(\"The number of words that are present in both glove vectors and our corpus are {} which \\\n",
        "is nearly {}% \".format(len(inter_words), np.round((float(len(inter_words))/len(words_source_train))\n",
        "*100)))\n",
        "\n",
        "words_corpus_source_train = {}\n",
        "words_glove = set(embeddings_index.keys())\n",
        "for i in words_source_train:\n",
        "  if i in words_glove:\n",
        "    words_corpus_source_train[i] = embeddings_index[i]\n",
        "print(\"word 2 vec length\", len(words_corpus_source_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all the words in the corpus 3665888\n",
            "the unique words in the corpus 90013\n",
            "The number of words that are present in both glove vectors and our corpus are 70834 which is nearly 79.0% \n",
            "word 2 vec length 70834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT_Ak7qtkv2_"
      },
      "source": [
        "def num(text):\n",
        "  words = [w for w in text.split() if not w in inter_words]\n",
        "  return len(words)\n",
        "\n",
        "data['unique_words'] = data['text'].apply(num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4RZLvQ00zBN"
      },
      "source": [
        "data = data[data['unique_words'] < 4]\n",
        "data.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "uF08PoBm1N78",
        "outputId": "b54f44b1-d68b-428c-d37d-37f691f00573"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "      <th>unique_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_START_ upgrad learner switches career ml al 9...</td>\n",
              "      <td>saurav kant alumnus upgrad iiit b pg program m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>_START_ delhi techie wins free food swiggy one...</td>\n",
              "      <td>kunal shah credit card bill payment platform c...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>_START_ new zealand end rohit sharma led india...</td>\n",
              "      <td>new zealand defeated india 8 wickets fourth od...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>_START_ aegon life iterm insurance plan helps ...</td>\n",
              "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>_START_ known hirani yrs metoo claims true son...</td>\n",
              "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97351</th>\n",
              "      <td>_START_ crpf jawan axed death maoists chhattis...</td>\n",
              "      <td>crpf jawan tuesday axed death sharp edged weap...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97352</th>\n",
              "      <td>_START_ first song sonakshi sinha noor titled ...</td>\n",
              "      <td>uff yeh first song sonakshi sinha starrer upc...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97353</th>\n",
              "      <td>_START_  the matrix film get reboot reports _END_</td>\n",
              "      <td>according reports new version 1999 science fic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97354</th>\n",
              "      <td>_START_ snoop dogg aims gun clown dressed trum...</td>\n",
              "      <td>new music video shows rapper snoop dogg aiming...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97355</th>\n",
              "      <td>_START_ madhesi morcha withdraws support nepal...</td>\n",
              "      <td>madhesi morcha alliance seven political partie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>97356 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               headlines  ... unique_words\n",
              "0      _START_ upgrad learner switches career ml al 9...  ...            0\n",
              "1      _START_ delhi techie wins free food swiggy one...  ...            2\n",
              "2      _START_ new zealand end rohit sharma led india...  ...            0\n",
              "3      _START_ aegon life iterm insurance plan helps ...  ...            0\n",
              "4      _START_ known hirani yrs metoo claims true son...  ...            1\n",
              "...                                                  ...  ...          ...\n",
              "97351  _START_ crpf jawan axed death maoists chhattis...  ...            0\n",
              "97352  _START_ first song sonakshi sinha noor titled ...  ...            2\n",
              "97353  _START_  the matrix film get reboot reports _END_  ...            0\n",
              "97354  _START_ snoop dogg aims gun clown dressed trum...  ...            0\n",
              "97355  _START_ madhesi morcha withdraws support nepal...  ...            0\n",
              "\n",
              "[97356 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JaGAWYn7kqR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(data['text'], data['headlines'], test_size = 0.2, random_state = 20)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_val, y_val, test_size = 0.5, random_state = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhoRlF5L_qwa"
      },
      "source": [
        "max_length_x = max(text_length)\n",
        "max_length_y = max(headlines_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXQdLrLK0l5B"
      },
      "source": [
        "x_t = Tokenizer()\n",
        "x_t.fit_on_texts(data['text'] + data['headlines'])\n",
        "x_vocab_size = len(x_t.word_index) + 1\n",
        "\n",
        "encoded_xtrain = x_t.texts_to_sequences(X_train)\n",
        "encoded_xval = x_t.texts_to_sequences(X_val)\n",
        "encoded_xtest = x_t.texts_to_sequences(X_test)\n",
        "\n",
        "padded_xtrain = pad_sequences(encoded_xtrain, maxlen=max_length_x, padding='post')\n",
        "padded_xval = pad_sequences(encoded_xval, maxlen=max_length_x, padding='post')\n",
        "padded_xtest = pad_sequences(encoded_xtest, maxlen=max_length_x, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7SVsptTNPtP"
      },
      "source": [
        "y_t = Tokenizer()\n",
        "y_t.fit_on_texts(data['headlines'])\n",
        "y_vocab_size = len(y_t.word_index) + 1\n",
        "\n",
        "encoded_ytrain = y_t.texts_to_sequences(y_train)\n",
        "encoded_yval = y_t.texts_to_sequences(y_val)\n",
        "encoded_ytest = y_t.texts_to_sequences(y_test)\n",
        "\n",
        "padded_ytrain = pad_sequences(encoded_ytrain, maxlen=max_length_y, padding='post')\n",
        "padded_yval = pad_sequences(encoded_yval, maxlen=max_length_y, padding='post')\n",
        "padded_ytest = pad_sequences(encoded_ytest, maxlen=max_length_y, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM-974HV0nKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa27890-eaf7-4e0f-e594-8057efa18be6"
      },
      "source": [
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embedding_matrix = np.zeros((x_vocab_size, glove_size))\n",
        "for word, i in x_t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 1917494 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99aPNL7dqnfh"
      },
      "source": [
        "### Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWuQ1AG8OdVL"
      },
      "source": [
        "class AttentionLayer(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "          \n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  \n",
        "            \n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            \n",
        "            fake_state = K.zeros_like(inputs)  \n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  \n",
        "            fake_state = K.expand_dims(fake_state)  \n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  \n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  \n",
        "\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTukjl0hpPgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6035a9eb-baac-43ff-a123-74e1ae1f02b7"
      },
      "source": [
        "latent_dim=500\n",
        "\n",
        "K.clear_session() \n",
        "\n",
        "encoder_inputs = Input(shape=(max_length_x,)) \n",
        "enc_emb = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False)(encoder_inputs) \n",
        "\n",
        "#LSTM \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "encoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "decoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 57)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 57, 300)      26975700    input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 57, 500), (N 1602000     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    26975700    input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 57, 500), (N 2002000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 500),  1602000     embedding_1[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_2[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 34779)  34813779    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 94,471,679\n",
            "Trainable params: 40,520,279\n",
            "Non-trainable params: 53,951,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fUJoaFAiwUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc22143-d3ed-4b87-e2e6-c44f3034a816"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "checkpoint_filepath = '/content/model.{epoch:02d}-{val_loss:.2f}.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True, save_freq = \"epoch\")\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "history=model.fit([padded_xtrain,padded_ytrain[:,:-1]], padded_ytrain.reshape(padded_ytrain.shape[0],padded_ytrain.shape[1], 1)[:,1:] ,epochs=30,batch_size=512, validation_data=([padded_xval,padded_yval[:,:-1]], padded_yval.reshape(padded_yval.shape[0],padded_yval.shape[1], 1)[:,1:]), callbacks=[es, model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "153/153 [==============================] - 188s 1s/step - loss: 4.7862 - val_loss: 4.4794\n",
            "Epoch 2/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 4.1536 - val_loss: 3.9571\n",
            "Epoch 3/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 3.6652 - val_loss: 3.6310\n",
            "Epoch 4/30\n",
            "153/153 [==============================] - 185s 1s/step - loss: 3.2448 - val_loss: 3.4038\n",
            "Epoch 5/30\n",
            "153/153 [==============================] - 185s 1s/step - loss: 2.8660 - val_loss: 3.2693\n",
            "Epoch 6/30\n",
            "153/153 [==============================] - 185s 1s/step - loss: 2.5345 - val_loss: 3.1968\n",
            "Epoch 7/30\n",
            "153/153 [==============================] - 185s 1s/step - loss: 2.2526 - val_loss: 3.1502\n",
            "Epoch 8/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 2.0222 - val_loss: 3.1206\n",
            "Epoch 9/30\n",
            "153/153 [==============================] - 185s 1s/step - loss: 1.8260 - val_loss: 3.1093\n",
            "Epoch 10/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 1.6569 - val_loss: 3.1080\n",
            "Epoch 11/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 1.5068 - val_loss: 3.1154\n",
            "Epoch 12/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 1.3725 - val_loss: 3.1404\n",
            "Epoch 13/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 1.2508 - val_loss: 3.1486\n",
            "Epoch 14/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 1.1415 - val_loss: 3.1837\n",
            "Epoch 15/30\n",
            "153/153 [==============================] - 184s 1s/step - loss: 1.0390 - val_loss: 3.2093\n",
            "Epoch 00015: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjfTbNZ06BIu"
      },
      "source": [
        "model1 = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model1.load_weights(\"model.h5\")\n",
        "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "history=model1.fit([padded_xtrain,padded_ytrain[:,:-1]], padded_ytrain.reshape(padded_ytrain.shape[0],padded_ytrain.shape[1], 1)[:,1:] ,epochs=30,batch_size=512, validation_data=([padded_xval,padded_yval[:,:-1]], padded_yval.reshape(padded_yval.shape[0],padded_yval.shape[1], 1)[:,1:]), callbacks=es)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CULXhQiGpvO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQf1v5WhqLLg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f5bfa510-79c7-465e-e371-ea5b36198da9"
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ0W3VZorHVK"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlSTzEbnskcd"
      },
      "source": [
        "reverse_target_word_index = y_t.index_word \n",
        "reverse_source_word_index = x_t.index_word \n",
        "target_word_index = y_t.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thX0Ep0Ssnd1"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_length_x,latent_dim))\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtU0wU8gsuz1"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    input_seq= input_seq.reshape(1,max_length_x)\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "  \n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        " \n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_length_y-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLyRVENRs2Ay"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXrWSc9Es5Qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e094bf-5b7a-4d2d-9042-f01c9390c8df"
      },
      "source": [
        "for i in range(10):\n",
        "  print(\"Review:\",seq2text(padded_xtest[i]))\n",
        "  print(\"Original summary:\",seq2summary(padded_ytest[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(padded_xtest[i]))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: spanish government introduce legislation criminalise sex without consent legislation consent would explicit states yes means yes anything else including silence means no move follows rape case verdict judges interpreted woman silence consent dropped rape charges accused \n",
            "Original summary: spain introduce law criminalise sex without consent \n",
            "Predicted summary:  germany bans sex public porn\n",
            "\n",
            "\n",
            "Review: 10th anniversary 26 11 mumbai terror attacks monday us president donald trump said the us stands people india quest justicewe never let terrorists win earlier us announced reward 5 million information leading arrest conviction individual involved attacks \n",
            "Original summary: us stands people india trump 10th anniversary 26 11 \n",
            "Predicted summary:  india us nation nation nation trump aide\n",
            "\n",
            "\n",
            "Review: yuvraj singh took social media share picture sachin tendulkar former india pacer ajit agarkar pre new year party picture sachin seen wearing wig glittering silver hat thanks sachintendulkar lovely night great fun monster agarkar yuvraj captioned picture \n",
            "Original summary: yuvraj shares pre new year party pic sachin agarkar \n",
            "Predicted summary:  sachin posts video yuvraj singh reveals picture\n",
            "\n",
            "\n",
            "Review: home affairs ministry wednesday said prime minister narendra modi expressed strong disapproval incidents toppling statues reported certain parts country adding ministry asked states take necessary measures prevent incidents said persons indulging acts must booked relevant provisions law \n",
            "Original summary: pm expressed disapproval statue toppling incidents mha \n",
            "Predicted summary:  fear destroyed northeast incident muslims pm modi\n",
            "\n",
            "\n",
            "Review: congress leader abhishek singhvi friday said congress leader sonia gandhi daughter priyanka gandhi vadra plays important role within party dismissing speculation priyanka contesting 2019 elections added priyanka role visible everyone comes congress leader salman khurshid reportedly said priyanka play a big role ahead 2019 elections \n",
            "Original summary: priyanka gandhi plays important role within party congress \n",
            "Predicted summary:  priyanka sonia gandhi sonia gandhi sonia gandhi\n",
            "\n",
            "\n",
            "Review: us based startup safkan developed headphone like wearable device claims remove excess earwax 35 seconds automated device called otoset uses suction clean ears comes disposable nozzle tips startup claims device designed reduce complications hearing loss membrane perforation \n",
            "Original summary: headphone like device clean ear wax 35 secs made \n",
            "Predicted summary:  startup makes device user 700 smart wearable device\n",
            "\n",
            "\n",
            "Review: sweden released feminist foreign policy manual government claimed launched 2014 in response discrimination systematic subordination faced women policy aims fight sexual violence women enhance political participation among others claims gender equality essential achieve peace security sustainable development \n",
            "Original summary: sweden releases feminist foreign policy manual \n",
            "Predicted summary:  japan launches first full physical sexual harassment\n",
            "\n",
            "\n",
            "Review: infosys reportedly made 100 crore counterclaim former cfo rajiv bansal breach trust non fulfilment obligations bansal moved court infosys withholding 1738 crore severance package infosys paid bansal 5 crore suspended remaining amount founder narayana murthy objected package claiming hush money \n",
            "Original summary: infosys files 100 crore claim ex cfo bansal report \n",
            "Predicted summary:  infosys pay 1217 cr cfo bansal kochhar ex cfo\n",
            "\n",
            "\n",
            "Review: india women team wicketkeeper sushma verma offered post deputy superintendent police himachal pradesh government cm virbhadra singh made announcement tuesday saying state proud achievement international cricket arena sushma hails shimla 15 dismissals keeper women world cup \n",
            "Original summary: india women keeper sushma verma offered dsp post hp govt \n",
            "Predicted summary:  india head coach mp cm declines\n",
            "\n",
            "\n",
            "Review: 17 lakh french nationals signed online petition president emmanuel macron plans give wife brigitte macron official first lady role move would give office staff allowance public purse with status first lady use role sees fit petition read \n",
            "Original summary: petition opposes official first lady role macron wife \n",
            "Predicted summary:  french prez offers royal citizenship lakh reward\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3Sfc9a422Rg"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km13viOn2P4t"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z516n1wQSgn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83eac699-47fc-4854-a02e-b39ed8af9f50"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "from scipy import spatial\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n",
        "sentence_encoder = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phm5tVv6yCZ9"
      },
      "source": [
        "def cosine_similarity(padded_xval, padded_yval):\n",
        "  scores = []\n",
        "  for i in range(len(padded_xval)):\n",
        "    \n",
        "    str1 = seq2summary(padded_yval[i])\n",
        "    str2 = decode_sequence(padded_xval[i])\n",
        "    embeddings = sentence_encoder([str1, str2]).numpy()\n",
        "    result = 1 - spatial.distance.cosine(embeddings[0], embeddings[1])\n",
        "    scores.append(result)\n",
        "  return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoB-bWnvcNC9",
        "outputId": "a83b5641-48b0-4ac3-916c-7a0b6d62f644"
      },
      "source": [
        "%%time\n",
        "scores = cosine_similarity(padded_xtest[:500],padded_ytest[:500] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 21s, sys: 6.54 s, total: 3min 27s\n",
            "Wall time: 3min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "mFysiYvWGre-",
        "outputId": "e9e8632a-0355-4ed5-e2f2-4be98f57ffec"
      },
      "source": [
        "np.mean(np.sort(scores)[-50:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63b971c1076e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEmUYsoBaqgx"
      },
      "source": [
        "np.mean(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CxZJ4LB2ZEW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2xI96Ts2ZXg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmyoWZmMI4OZ"
      },
      "source": [
        "import math\n",
        "import collections\n",
        "def bleu(pred_seq, label_seq, k): \n",
        "    \"\"\"Compute the BLEU.\"\"\"\n",
        "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
        "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
        "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
        "    for n in range(1, k + 1):\n",
        "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
        "        for i in range(len_label - n + 1):\n",
        "            label_subs[''.join(label_tokens[i:i + n])] += 1\n",
        "        for i in range(len_pred - n + 1):\n",
        "            if label_subs[''.join(pred_tokens[i:i + n])] > 0:\n",
        "                num_matches += 1\n",
        "                label_subs[''.join(pred_tokens[i:i + n])] -= 1\n",
        "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvsUaalTYDac"
      },
      "source": [
        "for i in range(0,5):\n",
        "  scoresbleu = []\n",
        "  s = bleu(seq2summary(padded_yval[i]),decode_sequence(padded_xval[i].reshape(1,max_length_x)),2)\n",
        "  scoresbleu.append(s)\n",
        "  print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZv8OpxGYDeu"
      },
      "source": [
        "scoresbleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK4q-baGHHhl"
      },
      "source": [
        "p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICg8N-6xHHn8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BLStTH4HHtr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT37DD2qYDjd"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf.fit([\"hi\", \"hello\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDm8ZqCJYDoZ"
      },
      "source": [
        "X = tfidf.transform([\"hi\", \"hello\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ4JB7nTYDsa"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3riUPQeNYDwN"
      },
      "source": [
        "print([X[1, tfidf.vocabulary_['hi']]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp319vKPYD0Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0mNzJ2-YD6a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z0JOU8JYD-n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJSIc7dVYEC4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KiQtQiczjdO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXa-QadC7CxH"
      },
      "source": [
        "sentence_embeddings = model([\"keep asking google assistant marry you google india users\",\"keep asking google assistant in modi google ai google india\"])\n",
        "embed=sentence_embeddings.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XaleL4O7C4K"
      },
      "source": [
        "embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8eA12sX7DDW"
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "dataSetI = embed[0]\n",
        "dataSetII = embed[1]\n",
        "result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBgZmCuT7DXK"
      },
      "source": [
        "import sklearn\n",
        "def cos(X,Y):\n",
        "  c = 0\n",
        "  for i in range(len(X)):\n",
        "      c += X[i]*Y[i]\n",
        "  cosine = c/ float((sum(X)*sum(Y))**0.5)\n",
        "  print(\"similarity: \", c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL-pYFzq0n6d"
      },
      "source": [
        "cos(embed[0],embed[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmM0BxDgYOoc"
      },
      "source": [
        "**Torch Req**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-pmlj-bYOoc"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h5klvqcCcG7"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU87EiEqYOoc"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9nNvklIYOod"
      },
      "source": [
        "def readLangs(text, summary):\n",
        "    \n",
        "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
        "\n",
        "    input_lang = Lang(text)\n",
        "    output_lang = Lang(summary)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-PfCX-qYOod"
      },
      "source": [
        "def prepareData(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
        "\n",
        "    print(f'Read {pairs} sentence pairs', end='\\n\\n')\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "    print(input_lang.name, input_lang.n_words, end='\\n\\n')\n",
        "    print(output_lang.name, output_lang.n_words, end='\\n\\n')\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap5M9WYtYOod"
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData(x, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY4PxrS24OOK"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lySRaaNwM8r3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ays-jqBMDhhk"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTST4a8CYOoe"
      },
      "source": [
        "MAX_LENGTH = 70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBaEileeYOoe"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAfjBTvLYOoe"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQheDzSXYOof"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax( self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pnwgITqYOof"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIDe9XZ2YOof"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]\n",
        "\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2gXkPYgYOog"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return f'{m}m {s}s'\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return f'Time: {asMinutes(s)} (ETA: {asMinutes(rs)})'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Uxp6YLYOog"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcWi8Dl0YOog"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=100, plot_every=100, learning_rate=0.01):\n",
        "    print(\"Training....\")\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # encoder_optimizer = optim.AdamW(encoder.parameters())\n",
        "    # decoder_optimizer = optim.AdamW(decoder.parameters())\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    \n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        if iter% 100 == 0:\n",
        "            print(iter,\"/\",n_iters + 1)\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            #print(f'{(timeSince(start, iter / n_iters)} (iter: {iter} percent: {iter / n_iters * 100}%%) %.4f', % print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwNFydmiYOog"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWrJlKfTYOoh"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('Text:       ', pair[0])\n",
        "        print('Summary:    ', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('Prediction: ', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Hs79qH4bbg"
      },
      "source": [
        "type(input_lang.n_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmmuQwHaYOoh"
      },
      "source": [
        "import random\n",
        "hidden_size = 200\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 500, print_every=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHFfbfqqYOoh"
      },
      "source": [
        "torch.save(encoder1.state_dict(), './enc.w')\n",
        "torch.save(attn_decoder1.state_dict(), './att.w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5HUdsm1YOoh"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPWr_mL8IKRN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}